Llama Indexæœ‰è®¸å¤šä½¿ç”¨æ¡ˆä¾‹ï¼ˆè¯­ä¹‰æœç´¢ï¼Œæ‘˜è¦ç­‰ï¼‰ï¼Œè¿™äº›éƒ½æœ‰[å¾ˆå¥½çš„æ–‡æ¡£](https://gpt-index.readthedocs.io/en/latest/use_cases/queries.html)ã€‚ä½†æ˜¯ï¼Œè¿™å¹¶ä¸æ„å‘³ç€æˆ‘ä»¬ä¸èƒ½å°†Llama Indexåº”ç”¨äºéå¸¸ç‰¹å®šçš„ç”¨ä¾‹ï¼

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥äº†è§£ä½¿ç”¨Llama Indexä»æ–‡æœ¬ä¸­æå–æœ¯è¯­å’Œå®šä¹‰çš„è®¾è®¡è¿‡ç¨‹ï¼ŒåŒæ—¶å…è®¸ç”¨æˆ·ç¨åæŸ¥è¯¢è¿™äº›æœ¯è¯­ã€‚ä½¿ç”¨[Streamlit](https://streamlit.io/)ï¼Œæˆ‘ä»¬å¯ä»¥æä¾›ä¸€ä¸ªæ˜“äºæ„å»ºçš„å‰ç«¯æ¥è¿è¡Œå’Œæµ‹è¯•æ‰€æœ‰è¿™äº›ï¼Œå¹¶å¿«é€Ÿè¿­ä»£æˆ‘ä»¬çš„è®¾è®¡ã€‚

æœ¬æ•™ç¨‹å‡å®šæ‚¨å·²å®‰è£…äº†Python3.9+å’Œä»¥ä¸‹è½¯ä»¶åŒ…ï¼š

- llama-index
- streamlit

åœ¨åŸºæœ¬å±‚é¢ä¸Šï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä»æ–‡æ¡£ä¸­æå–æœ¯è¯­å’Œå®šä¹‰ï¼Œç„¶åæä¾›ä¸€ç§æ–¹æ³•ï¼Œè®©ç”¨æˆ·æŸ¥è¯¢è¯¥æœ¯è¯­çŸ¥è¯†åº“å’Œå®šä¹‰ã€‚æœ¬æ•™ç¨‹å°†ä»‹ç»Llama Indexå’ŒStreamlitçš„åŠŸèƒ½ï¼Œå¹¶å¸Œæœ›ä¸ºå¸¸è§é—®é¢˜æä¾›ä¸€äº›æœ‰è¶£çš„è§£å†³æ–¹æ¡ˆã€‚

æœ¬æ•™ç¨‹çš„æœ€ç»ˆç‰ˆæœ¬å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/logan-markewich/llama_index_starter_pack)æ‰¾åˆ°ï¼Œå¹¶ä¸”å¯ä»¥åœ¨[Huggingface Spaces](https://huggingface.co/spaces/llamaindex/llama_index_term_definition_demo)ä¸Šæä¾›ä¸€ä¸ªåœ¨çº¿æ‰˜ç®¡æ¼”ç¤ºã€‚

## ä¸Šä¼ æ–‡æœ¬

ç¬¬ä¸€æ­¥æ˜¯ç»™ç”¨æˆ·æä¾›ä¸Šä¼ æ–‡æ¡£çš„æ–¹å¼ã€‚è®©æˆ‘ä»¬ä½¿ç”¨Streamlitç¼–å†™ä¸€äº›ä»£ç æ¥æä¾›è¿™ä¸ªç•Œé¢ï¼ä½¿ç”¨ä»¥ä¸‹ä»£ç å¹¶ä½¿ç”¨`streamlit run app.py`å¯åŠ¨åº”ç”¨ç¨‹åºã€‚

```python
import streamlit as st

st.title("ğŸ¦™ Llama Index Term Extractor ğŸ¦™")

document_text = st.text_area("Or enter raw text")
if st.button("Extract Terms and Definitions") and document_text:
    with st.spinner("Extracting..."):
        extracted_terms = document text  # this is a placeholder!
    st.write(extracted_terms)
```

å¤ªç®€å•äº†ï¼ä½†æ˜¯æ‚¨ä¼šæ³¨æ„åˆ°åº”ç”¨ç¨‹åºè¿˜æ²¡æœ‰åšä»»ä½•æœ‰ç”¨çš„äº‹æƒ…ã€‚è¦ä½¿ç”¨llama_indexï¼Œæˆ‘ä»¬è¿˜éœ€è¦è®¾ç½®OpenAI LLMã€‚LLMæœ‰å¾ˆå¤šå¯èƒ½çš„è®¾ç½®ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®©ç”¨æˆ·æ‰¾å‡ºæœ€å¥½çš„è®¾ç½®ã€‚æˆ‘ä»¬è¿˜åº”è¯¥è®©ç”¨æˆ·è®¾ç½®æå–æœ¯è¯­çš„æç¤ºï¼ˆè¿™ä¹Ÿå°†æœ‰åŠ©äºæˆ‘ä»¬è°ƒè¯•ä»€ä¹ˆæœ€å¥½ï¼‰ã€‚

## LLMè®¾ç½®

ä¸‹ä¸€æ­¥å¼•å…¥äº†ä¸€äº›æ ‡ç­¾åˆ°æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºï¼Œå°†å…¶åˆ†éš”ä¸ºæä¾›ä¸åŒåŠŸèƒ½çš„ä¸åŒçª—æ ¼ã€‚è®©æˆ‘ä»¬ä¸ºLLMè®¾ç½®å’Œä¸Šä¼ æ–‡æœ¬åˆ›å»ºä¸€ä¸ªæ ‡ç­¾ï¼š

```python
import os
import streamlit as st

DEFAULT_TERM_STR = (
    "Make a list of terms and definitions that are defined in the context, "
    "with one pair on each line. For example:

term1 - definition1
term2 - definition2
term3 - definition3

"
)

st.title("ğŸ¦™ Llama Index Term Extractor ğŸ¦™")

st.sidebar.title("Settings")
st.sidebar.markdown("## LLM Settings")
llm_prompt = st.sidebar.text_area("LLM Prompt", DEFAULT_TERM_STR)

st.title("Upload Text")
document_text = st.text_area("Or enter raw text")
if st.button("Extract Terms and Definitions") and document_text:
    with st.spinner("Extracting..."):
        extracted_terms = document text  # this is a placeholder!
    st.write(extracted_terms)
```st.title("ğŸ¦™ Llama Index Term Extractor ğŸ¦™")

setup_tab, upload_tab = st.tabs(["è®¾ç½®", "ä¸Šä¼ /æå–æœ¯è¯­"])

åœ¨setup_tabä¸­ï¼š
st.subheader("LLMè®¾ç½®")
api_key = st.text_input("åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥", type="password")
llm_name = st.selectbox('å“ªä¸ªLLMï¼Ÿ', ["text-davinci-003", "gpt-3.5-turbo", "gpt-4"])
model_temperature = st.slider("LLMæ¸©åº¦", min_value=0.0, max_value=1.0, step=0.1)
term_extract_str = st.text_area("ç”¨äºæå–æœ¯è¯­å’Œå®šä¹‰çš„æŸ¥è¯¢ã€‚", value=DEFAULT_TERM_STR)

åœ¨upload_tabä¸­ï¼š
st.subheader("æå–å’ŒæŸ¥è¯¢å®šä¹‰")
document_text = st.text_area("æˆ–è¾“å…¥åŸå§‹æ–‡æœ¬")
å¦‚æœst.button("æå–æœ¯è¯­å’Œå®šä¹‰")å’Œdocument_textï¼š
    with st.spinner("æå–ä¸­..."):
        extracted_terms = document text  # è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼
    st.write(extracted_terms)

ä»llama_indexå¯¼å…¥Documentï¼ŒGPTListIndexï¼ŒLLMPredictorï¼ŒServiceContextï¼ŒPromptHelperï¼Œload_index_from_storage

def get_llmï¼ˆllm_nameï¼Œmodel_temperatureï¼Œapi_keyï¼Œmax_tokens = 256ï¼‰ï¼š
    os.environ['OPENAI_API_KEY'] = api_key
    if llm_name == "text-davinci-003":
        return OpenAIï¼ˆtemperature = model_temperatureï¼Œmodel_name = llm_nameï¼Œmax_tokens = max_tokensï¼‰
    elseï¼š
        return ChatOpenAIï¼ˆtemperature = model_temperatureï¼Œmodel_name = llm_nameï¼Œmax_tokens = max_tokensï¼‰

def extract_termsï¼ˆdocumentsï¼Œterm_extract_strï¼Œllm_nameï¼Œmodel_temperatureï¼Œapi_keyï¼‰ï¼š
    llm = get_llmï¼ˆllm_nameï¼Œmodel_temperatureï¼Œapi_keyï¼Œmax_tokens = 1024ï¼‰

    service_context = ServiceContext.from_defaultsï¼ˆllm_predictor = LLMPredictorï¼ˆllm = llmï¼‰ï¼Œ
                                                   prompt_helper = PromptHelperï¼ˆmax_input_size = 4096ï¼Œ
                                                                              max_chunk_overlap = 20ï¼Œç°åœ¨ï¼Œä½¿ç”¨æ–°çš„å‡½æ•°ï¼Œæˆ‘ä»¬ç»ˆäºå¯ä»¥æå–æˆ‘ä»¬çš„æœ¯è¯­äº†ï¼

```python
...
with upload_tab:
    st.subheader("æå–å’ŒæŸ¥è¯¢å®šä¹‰")
    document_text = st.text_area("æˆ–è¾“å…¥åŸå§‹æ–‡æœ¬")
    if st.button("æå–æœ¯è¯­å’Œå®šä¹‰") and document_text:
        with st.spinner("æå–ä¸­..."):
            extracted_terms = extract_terms([Document(document_text)],
                                            term_extract_str, llm_name,
                                            model_temperature, api_key)
        st.write(extracted_terms)
```

ç°åœ¨å‘ç”Ÿäº†å¾ˆå¤šäº‹æƒ…ï¼Œè®©æˆ‘ä»¬èŠ±ä¸€ç‚¹æ—¶é—´æ¥å›é¡¾ä¸€ä¸‹å‘ç”Ÿäº†ä»€ä¹ˆã€‚

`get_llm()`æ ¹æ®è®¾ç½®é€‰é¡¹å¡ä¸­çš„ç”¨æˆ·é…ç½®å®ä¾‹åŒ–LLMã€‚æ ¹æ®æ¨¡å‹åç§°ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨é€‚å½“çš„ç±»ï¼ˆ`OpenAI`ä¸`ChatOpenAI`ï¼‰ã€‚

`extract_terms()`æ˜¯æ‰€æœ‰å¥½ä¸œè¥¿å‘ç”Ÿçš„åœ°æ–¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨`max_tokens = 1024`è°ƒç”¨`get_llm()`ï¼Œå› ä¸ºæˆ‘ä»¬ä¸æƒ³åœ¨æå–æœ¯è¯­å’Œå®šä¹‰æ—¶è¿‡å¤šé™åˆ¶æ¨¡å‹ï¼ˆå¦‚æœæœªè®¾ç½®ï¼Œé»˜è®¤å€¼ä¸º256ï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„`ServiceContext`å¯¹è±¡ï¼Œå°†`num_output`ä¸æˆ‘ä»¬çš„`max_tokens`å€¼å¯¹é½ï¼Œå¹¶å°†å—å¤§å°è®¾ç½®ä¸ºä¸å¤§äºè¾“å‡ºã€‚å½“æ–‡æ¡£ç”±Llama Indexç´¢å¼•æ—¶ï¼Œå¦‚æœå®ƒä»¬å¾ˆå¤§ï¼Œå®ƒä»¬å°†è¢«åˆ†å‰²æˆå—ï¼ˆä¹Ÿç§°ä¸ºèŠ‚ç‚¹ï¼‰ï¼Œå¹¶ä¸”`chunk_size_limit`è®¾ç½®äº†è¿™äº›å—çš„æœ€å¤§å¤§å°ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸´æ—¶åˆ—è¡¨ç´¢å¼•å¹¶ä¼ å…¥æˆ‘ä»¬çš„æœåŠ¡ä¸Šä¸‹æ–‡ã€‚åˆ—è¡¨ç´¢å¼•å°†è¯»å–ç´¢å¼•ä¸­çš„æ¯ä¸€ä¸ªæ–‡æœ¬ï¼Œè¿™å¯¹äºæå–æœ¯è¯­éå¸¸å®Œç¾ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨é¢„å®šä¹‰çš„æŸ¥è¯¢æ–‡æœ¬ä½¿ç”¨`response_mode =â€œtree_summarizeâ€`æå–æœ¯è¯­ã€‚æ­¤å“åº”æ¨¡å¼å°†ä»åº•éƒ¨å¼€å§‹ç”Ÿæˆæ‘˜è¦æ ‘ï¼Œå…¶ä¸­æ¯ä¸ªçˆ¶çº§æ¦‚æ‹¬å…¶å­çº§ã€‚æœ€åï¼Œè¿”å›æ ‘çš„é¡¶éƒ¨ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰æå–çš„æœ¯è¯­å’Œå®šä¹‰ã€‚æœ€åï¼Œæˆ‘ä»¬åšä¸€äº›å°çš„åå¤„ç†ã€‚æˆ‘ä»¬å‡è®¾æ¨¡å‹æŒ‰ç…§è¯´æ˜æ‰§è¡Œï¼Œå¹¶åœ¨æ¯è¡Œæ”¾ç½®ä¸€ä¸ªæœ¯è¯­/å®šä¹‰å¯¹ã€‚å¦‚æœç¼ºå°‘`Termï¼š`æˆ–`Definitionï¼š`æ ‡ç­¾ï¼Œæˆ‘ä»¬å°†è·³è¿‡å®ƒã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿äºå­˜å‚¨ï¼

## ä¿å­˜æå–çš„æœ¯è¯­

æ—¢ç„¶æˆ‘ä»¬å¯ä»¥æå–æœ¯è¯­ï¼Œæˆ‘ä»¬éœ€è¦å°†å®ƒä»¬æ”¾åœ¨æŸä¸ªåœ°æ–¹ï¼Œä»¥ä¾¿ä»¥åå¯ä»¥æŸ¥è¯¢å®ƒä»¬ã€‚ `GPTVectorStoreIndex`åº”è¯¥æ˜¯ç°åœ¨çš„å®Œç¾é€‰æ‹©ï¼ä½†æ˜¯æ­¤å¤–ï¼Œæˆ‘ä»¬çš„åº”ç”¨ç¨‹åºè¿˜åº”è¯¥è·Ÿè¸ªå“ªäº›æœ¯è¯­è¢«æ’å…¥ç´¢å¼•ï¼Œä»¥ä¾¿ä»¥åå¯ä»¥æ£€æŸ¥å®ƒä»¬ã€‚ä½¿ç”¨`st.session_state`ï¼Œæˆ‘ä»¬å¯ä»¥å°†å½“å‰çš„æœ¯è¯­åˆ—è¡¨å­˜å‚¨åœ¨æ¯ä¸ªç”¨æˆ·çš„ä¼šè¯å­—å…¸ä¸­ï¼

é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªåŠŸèƒ½æ¥åˆå§‹åŒ–å…¨å±€å‘é‡ç´¢å¼•ï¼Œä»¥åŠå¦ä¸€ä¸ªå‡½æ•°æ¥æ’å…¥æå–çš„æœ¯è¯­ã€‚

```python
...
å¦‚æœ'st.session_state'ä¸­æ²¡æœ‰'all_terms'ï¼Œåˆ™st.session_state['all_terms'] = DEFAULT_TERMS
...

def insert_terms(terms_to_definition):
    å¯¹äºterms_to_definitionä¸­çš„termå’Œdefinitionï¼Œ
    doc = Document(f"Term: {term}\nDefinition: {definition}")
    st.session_state['llama_index'].insert(doc)

@st.cache_resource
def initialize_index(llm_name, model_temperature, api_key):
    """Create the GPTSQLStructStoreIndex object."""
    llm = get_llm(llm_name, model_temperature, api_key)

    service_context = ServiceContext.from_defaults(llm_predictor=LLMPredictor(llm=llm))

    index = GPTVectorStoreIndex([], service_context=service_context)

    return index

...

with upload_tab:
    st.subheader("æå–å’ŒæŸ¥è¯¢å®šä¹‰")
    å¦‚æœst.button("åˆå§‹åŒ–ç´¢å¼•å¹¶é‡ç½®æœ¯è¯­"):
        st.session_state['llama_index'] = initialize_index(llm_name, model_temperature, api_key)
        st.session_state['all_terms'] = {}

    å¦‚æœ'st.session_state'ä¸­æœ‰"llama_index"ï¼š
        st.markdown("ä¸Šä¼ æ–‡æ¡£çš„å›¾åƒ/å±å¹•æˆªå›¾ï¼Œæˆ–æ‰‹åŠ¨è¾“å…¥æ–‡æœ¬ã€‚")
        document_text = st.text_area("æˆ–è¾“å…¥åŸå§‹æ–‡æœ¬")
        å¦‚æœst.button("æå–æœ¯è¯­å’Œå®šä¹‰")å¹¶ä¸”ï¼ˆuploaded_fileæˆ–document_textï¼‰ï¼š
            st.session_state['terms'] = {}
            terms_docs = {}
            with st.spinner("æå–ä¸­..."):
                terms_docs.update(extract_terms([Document(document_text)], term_extract_str, llm_name, model_temperature, api_key))
            st.session_state['terms'].update(terms_docs)

        å¦‚æœ'st.session_state'ä¸­æœ‰"terms"å¹¶ä¸”st.session_state["terms"]ï¼š
            st.markdown("æå–çš„æœ¯è¯­")
            st.json(st.session_state['terms'])

            å¦‚æœst.button("æ’å…¥æœ¯è¯­ï¼Ÿ")ï¼šç°åœ¨ä½ çœŸçš„å¼€å§‹åˆ©ç”¨streamlitçš„å¼ºå¤§åŠŸèƒ½äº†ï¼è®©æˆ‘ä»¬ä»ä¸Šä¼ é€‰é¡¹å¡ä¸‹çš„ä»£ç å¼€å§‹ã€‚æˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªæŒ‰é’®æ¥åˆå§‹åŒ–å‘é‡ç´¢å¼•ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨å…¨å±€streamlitçŠ¶æ€å­—å…¸ä¸­ï¼ŒåŒæ—¶é‡ç½®å½“å‰æå–çš„æœ¯è¯­ã€‚ç„¶åï¼Œä»è¾“å…¥æ–‡æœ¬ä¸­æå–æœ¯è¯­åï¼Œæˆ‘ä»¬å°†å…¶å­˜å‚¨åœ¨å…¨å±€çŠ¶æ€ä¸­ï¼Œå¹¶ç»™ç”¨æˆ·ä¸€ä¸ªæœºä¼šåœ¨æ’å…¥ä¹‹å‰æŸ¥çœ‹å®ƒä»¬ã€‚å¦‚æœæŒ‰ä¸‹æ’å…¥æŒ‰é’®ï¼Œåˆ™æˆ‘ä»¬è°ƒç”¨æ’å…¥æœ¯è¯­å‡½æ•°ï¼Œæ›´æ–°æˆ‘ä»¬çš„å…¨å±€è·Ÿè¸ªæ’å…¥æœ¯è¯­ï¼Œå¹¶ä»ä¼šè¯çŠ¶æ€ä¸­åˆ é™¤æœ€è¿‘æå–çš„æœ¯è¯­ã€‚

## æŸ¥è¯¢æå–çš„æœ¯è¯­/å®šä¹‰

æå–å¹¶ä¿å­˜äº†æœ¯è¯­å’Œå®šä¹‰ï¼Œæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Ÿç”¨æˆ·åˆå¦‚ä½•è®°ä½ä»¥å‰ä¿å­˜çš„å†…å®¹ï¼Ÿï¼Ÿæˆ‘ä»¬å¯ä»¥ç®€å•åœ°åœ¨åº”ç”¨ç¨‹åºä¸­æ·»åŠ ä¸€äº›æ›´å¤šçš„é€‰é¡¹å¡æ¥å¤„ç†è¿™äº›åŠŸèƒ½ã€‚

...
setup_tabï¼Œterms_tabï¼Œupload_tabï¼Œquery_tab = st.tabsï¼ˆ
    ["è®¾ç½®"ï¼Œ"æ‰€æœ‰æœ¯è¯­"ï¼Œ"ä¸Šä¼ /æå–æœ¯è¯­"ï¼Œ"æŸ¥è¯¢æœ¯è¯­"]
ï¼‰
...
with terms_tabï¼š
    with terms_tabï¼š
    st.subheaderï¼ˆ"å½“å‰æå–çš„æœ¯è¯­å’Œå®šä¹‰"ï¼‰
    st.jsonï¼ˆst.session_state ["all_terms"]ï¼‰
...
with query_tabï¼š
    st.subheaderï¼ˆ"æŸ¥è¯¢æœ¯è¯­/å®šä¹‰ï¼"ï¼‰
    st.markdownï¼ˆ
        ï¼ˆ
            "LLMå°†å°è¯•å›ç­”æ‚¨çš„æŸ¥è¯¢ï¼Œå¹¶ä½¿ç”¨æ‚¨æ’å…¥çš„æœ¯è¯­/å®šä¹‰æ¥å¢å¼ºå®ƒçš„ç­”æ¡ˆã€‚"
            "å¦‚æœç´¢å¼•ä¸­æ²¡æœ‰è¯¥æœ¯è¯­ï¼Œå®ƒå°†ä½¿ç”¨å…¶å†…éƒ¨çŸ¥è¯†å›ç­”æŸ¥è¯¢ã€‚"
        ï¼‰
    ï¼‰
    å¦‚æœst.buttonï¼ˆ"åˆå§‹åŒ–ç´¢å¼•å¹¶é‡ç½®æœ¯è¯­"ï¼Œkey ="init_index_2"ï¼‰ï¼š
        st.session_state ["llama_index"] = initialize_indexï¼ˆ
            llm_nameï¼Œmodel_temperatureï¼Œapi_key
        ï¼‰
        st.session_state ["all_terms"] = {}

    å¦‚æœ"llama_index"åœ¨st.session_stateä¸­ï¼š
        query_text = st.text_inputï¼ˆ"æŸ¥è¯¢æœ¯è¯­æˆ–å®šä¹‰ï¼š"ï¼‰
        å¦‚æœquery_textï¼š
            query_text = query_text + "\nå¦‚æœæ‚¨æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè¯·æ ¹æ®æ‚¨çš„æœ€ä½³çŸ¥è¯†å›ç­”æŸ¥è¯¢ã€‚"
            with st.spinnerï¼ˆ"ç”Ÿæˆç­”æ¡ˆ..."ï¼‰ï¼š
                response = st.session_state ["llama_index"]ã€‚queryï¼ˆ
                    query_textï¼Œsimilarity_top_k = 5ï¼Œresponse_mode ="compact"
                ï¼‰
            st.markdownï¼ˆstrï¼ˆresponseï¼‰ï¼‰
```

è™½ç„¶è¿™ä¸»è¦æ˜¯åŸºæœ¬çš„ï¼Œä½†è¦æ³¨æ„ä¸€äº›é‡è¦çš„äº‹æƒ…ï¼š

- æˆ‘ä»¬çš„åˆå§‹åŒ–ä½†è¿™ä¸ªæŒ‰é’®ä¸æˆ‘ä»¬çš„å…¶ä»–æŒ‰é’®å…·æœ‰ç›¸åŒçš„æ–‡æœ¬ã€‚Streamlitä¼šå¯¹æ­¤æŠ±æ€¨ï¼Œå› æ­¤æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå”¯ä¸€çš„é”®ã€‚
- æŸ¥è¯¢ä¸­æ·»åŠ äº†ä¸€äº›é™„åŠ æ–‡æœ¬ï¼è¿™æ˜¯ä¸ºäº†å°è¯•å¼¥è¡¥ç´¢å¼•æ²¡æœ‰ç­”æ¡ˆçš„æƒ…å†µã€‚
- åœ¨æˆ‘ä»¬çš„ç´¢å¼•æŸ¥è¯¢ä¸­ï¼Œæˆ‘ä»¬æŒ‡å®šäº†ä¸¤ä¸ªé€‰é¡¹ï¼š
  - `similarity_top_k=5`æ„å‘³ç€ç´¢å¼•å°†è·å–ä¸æŸ¥è¯¢æœ€æ¥è¿‘çš„5ä¸ªæœ€åŒ¹é…çš„æœ¯è¯­/å®šä¹‰ã€‚
  - `response_mode="compact"`æ„å‘³ç€å°†å°½å¯èƒ½å¤šçš„æ–‡æœ¬ä»5ä¸ªåŒ¹é…çš„æœ¯è¯­/å®šä¹‰ä¸­ç”¨äºæ¯ä¸ªLLMè°ƒç”¨ã€‚å¦‚æœæ²¡æœ‰è¿™ä¸ªï¼Œç´¢å¼•å°†è‡³å°‘å¯¹LLMè¿›è¡Œ5æ¬¡è°ƒç”¨ï¼Œè¿™å¯èƒ½ä¼šå‡æ…¢ç”¨æˆ·çš„é€Ÿåº¦ã€‚

## å¹²é¢„æµ‹è¯•

å—¯ï¼Œå®é™…ä¸Šæˆ‘å¸Œæœ›ä½ ä¸€ç›´åœ¨æµ‹è¯•ã€‚ä½†ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•ä¸€æ¬¡å®Œæ•´çš„æµ‹è¯•ã€‚

1. åˆ·æ–°åº”ç”¨ç¨‹åº
2. è¾“å…¥æ‚¨çš„LLMè®¾ç½®
3. è½¬åˆ°æŸ¥è¯¢é€‰é¡¹å¡
4. è¯¢é—®ä»¥ä¸‹å†…å®¹ï¼šâ€œä»€ä¹ˆæ˜¯bunnyhugï¼Ÿâ€
5. åº”ç”¨ç¨‹åºåº”è¯¥ç»™å‡ºä¸€äº›æ— æ„ä¹‰çš„å›å¤ã€‚å¦‚æœä½ ä¸çŸ¥é“ï¼Œbunnyhugæ˜¯åŠ æ‹¿å¤§å¤§å¹³åŸäººç”¨æ¥æè¿°è¿å¸½è¡«çš„å¦ä¸€ä¸ªè¯ï¼
6. è®©æˆ‘ä»¬å°†è¿™ä¸ªå®šä¹‰æ·»åŠ åˆ°åº”ç”¨ç¨‹åºä¸­ã€‚æ‰“å¼€ä¸Šä¼ é€‰é¡¹å¡ï¼Œè¾“å…¥ä»¥ä¸‹æ–‡æœ¬ï¼šâ€œBunnyhugæ˜¯ä¸€ä¸ªå¸¸ç”¨æœ¯è¯­ï¼Œç”¨æ¥æè¿°è¿å¸½è¡«ã€‚è¿™ä¸ªæœ¯è¯­æ˜¯ç”±åŠ æ‹¿å¤§å¤§å¹³åŸäººä½¿ç”¨çš„ã€‚â€
7. å•å‡»æå–æŒ‰é’®ã€‚å‡ åˆ†é’Ÿåï¼Œåº”ç”¨ç¨‹åºåº”è¯¥æ˜¾ç¤ºæ­£ç¡®æå–çš„æœ¯è¯­/å®šä¹‰ã€‚å•å‡»æ’å…¥æœ¯è¯­æŒ‰é’®ä»¥ä¿å­˜ï¼
8. å¦‚æœæˆ‘ä»¬æ‰“å¼€æœ¯è¯­é€‰é¡¹å¡ï¼Œåˆšåˆšæå–çš„æœ¯è¯­å’Œå®šä¹‰åº”è¯¥ä¼šæ˜¾ç¤º
9. å›åˆ°æŸ¥è¯¢é€‰é¡¹å¡ï¼Œå°è¯•é—®ä»€ä¹ˆæ˜¯bunnyhugã€‚ç°åœ¨ï¼Œç­”æ¡ˆåº”è¯¥æ˜¯æ­£ç¡®çš„ï¼

## æ”¹è¿›#1 - åˆ›å»ºä¸€ä¸ªèµ·ç‚¹ç´¢å¼•

éšç€æˆ‘ä»¬çš„åŸºæœ¬åº”ç”¨ç¨‹åºæ­£å¸¸å·¥ä½œï¼Œå»ºç«‹ä¸€ä¸ªæœ‰ç”¨çš„ç´¢å¼•å¯èƒ½ä¼šæ„Ÿè§‰å¾ˆç´¯ã€‚å¦‚æœæˆ‘ä»¬ç»™ç”¨æˆ·æä¾›ä¸€äº›èµ·ç‚¹æ¥å±•ç¤ºåº”ç”¨ç¨‹åºçš„æŸ¥è¯¢åŠŸèƒ½æ€ä¹ˆåŠï¼Ÿæˆ‘ä»¬å¯ä»¥åšåˆ°ï¼é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¹æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºåšä¸€äº›å°çš„æ”¹å˜ï¼Œä»¥ä¾¿æˆ‘ä»¬åœ¨æ¯æ¬¡ä¸Šä¼ åå°†ç´¢å¼•ä¿å­˜åˆ°ç£ç›˜ï¼š

```python
def insert_terms(terms_to_definition):
    for term, definition in terms_to_definition.items():
        doc = Document(f"Term: {term}\nDefinition: {definition}")
        st.session_state['llama_index'].insert(doc)
    # TEMPORARY - save to disk
    st.session_state['llama_index'].storage_context.persist()
```

ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›æ–‡æ¡£æ¥æå–ï¼æœ¬é¡¹ç›®çš„å­˜å‚¨åº“ä½¿ç”¨äº†æœ‰å…³çº½çº¦å¸‚çš„ç»´åŸºç™¾ç§‘é¡µé¢ï¼Œæ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/jerryjliu/llama_index/blob/main/examples/test_wiki/data/nyc_text.txt)æ‰¾åˆ°æ–‡æœ¬ã€‚

å¦‚æœæ‚¨å°†æ–‡æœ¬ç²˜è´´åˆ°ä¸Šä¼ é€‰é¡¹å¡ä¸­å¹¶è¿è¡Œå®ƒï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æ’å…¥æå–çš„teä»langchain.chains.prompt_selecä¸­ï¼Œç¡®ä¿ä¹Ÿå°†æå–çš„æœ¯è¯­çš„æ–‡æœ¬å¤åˆ¶åˆ°è®°äº‹æœ¬æˆ–ç±»ä¼¼çš„æ–‡ä»¶ä¸­ï¼Œç„¶åå†æ’å…¥ç´¢å¼•ï¼æˆ‘ä»¬é©¬ä¸Šå°±éœ€è¦å®ƒä»¬äº†ã€‚æ’å…¥åï¼Œåˆ é™¤æˆ‘ä»¬ç”¨æ¥å°†ç´¢å¼•ä¿å­˜åˆ°ç£ç›˜çš„ä»£ç è¡Œã€‚ç°åœ¨å·²ç»ä¿å­˜äº†èµ·å§‹ç´¢å¼•ï¼Œæˆ‘ä»¬å¯ä»¥ä¿®æ”¹æˆ‘ä»¬çš„â€œinitialize_indexâ€å‡½æ•°ï¼Œçœ‹èµ·æ¥åƒè¿™æ ·ï¼š

```python
@st.cache_resource
def initialize_index(llm_name, model_temperature, api_key):
    """Create the GPTSQLStructStoreIndex object."""
    llm = get_llm(llm_name, model_temperature, api_key)

    service_context = ServiceContext.from_defaults(llm_predictor=LLMPredictor(llm=llm))

    index = load_index_from_storage(service_context=service_context)

    return index
```

ä½ è®°å¾—æŠŠé‚£ä¸ªå·¨å¤§çš„æå–æœ¯è¯­åˆ—è¡¨ä¿å­˜åœ¨è®°äº‹æœ¬é‡Œå—ï¼Ÿç°åœ¨ï¼Œå½“æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºåˆå§‹åŒ–æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›å°†ç´¢å¼•ä¸­çš„é»˜è®¤æœ¯è¯­ä¼ é€’ç»™æˆ‘ä»¬çš„å…¨å±€æœ¯è¯­çŠ¶æ€ï¼š

```python
...
if "all_terms" not in st.session_state:
    st.session_state["all_terms"] = DEFAULT_TERMS
...
```

åœ¨ä»¥å‰é‡ç½®â€œall_termsâ€å€¼çš„ä»»ä½•åœ°æ–¹é‡å¤ä»¥ä¸Šå†…å®¹ã€‚

## æ”¹è¿›#2 -ï¼ˆç»†åŒ–ï¼‰æ›´å¥½çš„æç¤º

ç°åœ¨ï¼Œå¦‚æœä½ ç©ä¸€ä¸‹è¿™ä¸ªåº”ç”¨ç¨‹åºï¼Œä½ å¯èƒ½ä¼šæ³¨æ„åˆ°å®ƒä¸å†éµå¾ªæˆ‘ä»¬çš„æç¤ºï¼è®°ä½ï¼Œæˆ‘ä»¬å‘æˆ‘ä»¬çš„â€œquery_strâ€å˜é‡æ·»åŠ äº†ï¼Œå¦‚æœæ‰¾ä¸åˆ°æœ¯è¯­/å®šä¹‰ï¼Œå°±æŒ‰ç…§å®ƒçš„æœ€ä½³çŸ¥è¯†å›ç­”ã€‚ä½†æ˜¯ç°åœ¨ï¼Œå¦‚æœä½ å°è¯•æŸ¥è¯¢éšæœºæœ¯è¯­ï¼ˆæ¯”å¦‚bunnyhugï¼ï¼‰ï¼Œå®ƒå¯èƒ½ä¼šéµå¾ªè¿™äº›æŒ‡ä»¤ï¼Œä¹Ÿå¯èƒ½ä¸ä¼šéµå¾ªè¿™äº›æŒ‡ä»¤ã€‚

è¿™æ˜¯ç”±äºâ€œç»†åŒ–â€ç­”æ¡ˆçš„æ¦‚å¿µã€‚ç”±äºæˆ‘ä»¬åœ¨å‰5ä¸ªåŒ¹é…ç»“æœä¸­æŸ¥è¯¢ï¼Œæœ‰æ—¶æ‰€æœ‰ç»“æœéƒ½ä¸é€‚åˆå•ä¸ªæç¤ºï¼OpenAIæ¨¡å‹é€šå¸¸å…·æœ‰4097ä¸ªä»¤ç‰Œçš„æœ€å¤§è¾“å…¥å¤§å°ã€‚å› æ­¤ï¼ŒLlama Indexé€šè¿‡å°†åŒ¹é…ç»“æœåˆ†å‰²ä¸ºé€‚åˆæç¤ºçš„å—æ¥è§£å†³æ­¤é—®é¢˜ã€‚ Llama Indexä»ç¬¬ä¸€ä¸ªAPIè°ƒç”¨è·å¾—åˆå§‹ç­”æ¡ˆåï¼Œå°†ä¸‹ä¸€å—å‘é€åˆ°APIï¼Œå¹¶ä¸”ä½¿ç”¨å…ˆå‰çš„ç­”æ¡ˆå‘æ¨¡å‹è¯·æ±‚ç»†åŒ–è¯¥ç­”æ¡ˆã€‚

å› æ­¤ï¼Œç»†åŒ–è¿‡ç¨‹ä¼¼ä¹æ­£åœ¨ç ´åæˆ‘ä»¬çš„ç»“æœï¼ä¸è¦å°†é¢å¤–çš„æŒ‡ä»¤é™„åŠ åˆ°â€œquery_strâ€ä¸­ï¼Œè€Œæ˜¯åˆ é™¤å®ƒï¼ŒLlama Indexå°†å…è®¸æˆ‘ä»¬æä¾›è‡ªå·±çš„è‡ªå®šä¹‰æç¤ºï¼ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨[é»˜è®¤æç¤º]ï¼ˆhttps://github.com/jerryjliu/llama_index/blob/main/llama_index/prompts/default_prompts.pyï¼‰å’Œ[èŠå¤©ç‰¹å®šæç¤º]ï¼ˆhttps://github.com/jerryjliu/llama_index/blob/main/llama_index/prompts/chat_prompts.pyï¼‰ä½œä¸ºæŒ‡å—åˆ›å»ºå®ƒä»¬ã€‚ä½¿ç”¨ä¸€ä¸ªæ–°çš„æ–‡ä»¶â€œconstants.pyâ€ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€äº›æ–°çš„æŸ¥è¯¢æ¨¡æ¿ï¼š

```python
from langchain.chains.prompt_selecè¿™çœ‹èµ·æ¥åƒå¾ˆå¤šä»£ç ï¼Œä½†å…¶å®å¹¶ä¸å¤æ‚ï¼å¦‚æœä½ çœ‹è¿‡é»˜è®¤æç¤ºï¼Œä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°æœ‰é»˜è®¤æç¤ºï¼Œä¹Ÿæœ‰é’ˆå¯¹èŠå¤©æ¨¡å‹çš„æç¤ºã€‚ç»§ç»­è¿™ä¸€è¶‹åŠ¿ï¼Œæˆ‘ä»¬ä¹Ÿä¸ºæˆ‘ä»¬çš„è‡ªå®šä¹‰æç¤ºåšåŒæ ·çš„äº‹æƒ…ã€‚ç„¶åï¼Œä½¿ç”¨æç¤ºé€‰æ‹©å™¨ï¼Œæˆ‘ä»¬å¯ä»¥ç»„åˆæˆ‘ä»¬çš„è‡ªå®šä¹‰æç¤ºï¼Œä»¥ä¾¿åœ¨ä¸åŒçš„æ¨¡å‹ä¸­ä½¿ç”¨ã€‚æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸¤ä¸ªæç¤ºåˆå¹¶ä¸ºä¸€ä¸ªå¯¹è±¡ã€‚å¦‚æœä½¿ç”¨çš„LLMæ˜¯èŠå¤©æ¨¡å‹ï¼ˆChatGPTï¼ŒGPT-4ï¼‰ï¼Œåˆ™ä½¿ç”¨èŠå¤©æç¤ºã€‚å¦åˆ™ï¼Œä½¿ç”¨æ­£å¸¸çš„æç¤ºæ¨¡æ¿ã€‚

å¦å¤–è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬åªå®šä¹‰äº†ä¸€ä¸ªQAæ¨¡æ¿ã€‚åœ¨èŠå¤©æ¨¡å‹ä¸­ï¼Œè¿™å°†è¢«è½¬æ¢ä¸ºä¸€æ¡â€œäººç±»â€æ¶ˆæ¯ã€‚

å› æ­¤ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æç¤ºå¯¼å…¥æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºï¼Œå¹¶åœ¨æŸ¥è¯¢æœŸé—´ä½¿ç”¨å®ƒä»¬ã€‚

å¦‚æœä½ å†å¤šå°è¯•ä¸€äº›æŸ¥è¯¢ï¼Œå¸Œæœ›ä½ ä¼šæ³¨æ„åˆ°ç°åœ¨çš„å“åº”æ›´åŠ éµå¾ªæˆ‘ä»¬çš„æŒ‡ç¤ºï¼

## æ”¹è¿›#3 - å›¾åƒæ”¯æŒ

Llama indexä¹Ÿæ”¯æŒå›¾åƒï¼ä½¿ç”¨Llama Indexï¼Œæˆ‘ä»¬å¯ä»¥ä¸Šä¼ æ–‡æ¡£ï¼ˆè®ºæ–‡ï¼Œä¿¡ä»¶ç­‰ï¼‰çš„å›¾åƒï¼ŒLlama Indexå¤„ç†æå–æ–‡æœ¬ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œä¹Ÿå…è®¸ç”¨æˆ·ä¸Šä¼ ä»–ä»¬æ–‡æ¡£çš„å›¾åƒï¼Œå¹¶ä»ä¸­æå–æœ¯è¯­å’Œå®šä¹‰ã€‚

å¦‚æœä½ å¾—åˆ°ä¸€ä¸ªå…³äºPILçš„å¯¼å…¥é”™è¯¯ï¼Œé¦–å…ˆä½¿ç”¨`pip install Pillow`å®‰è£…å®ƒã€‚

```python
from PIL import Image
from llama_index.readers.file.base import DEFAULT_FILE_EXTRACTOR, ImageParser

@st.cache_resource
def get_file_extractor():
    image_parser = ImageParser(keep_image=True, parse_text=True)
    file_extractor = DEFAULT_FILE_EXTRACTOR
    file_extractor.update(
        {
            ".jpg": image_parser,
            ".png": image_parser,
            ".jpeg": image_parser,
        }
    )

    return file_extractor

file_extractor = get_file_extractor()
...
with upload_tab:
    st.subheader("Extract and Query Definitions")
    if st.button("Initialize Index and Reset Terms", key="init_index_1"):
        st.session_state["llama_index"] = initialize_index(
            llm_name, model_temperature, api_key
        )
        st.session_state["all_terms"] = DEFAULT_TERMS

    if "llama_index" in st.session_state:
        st.markdown(
            "Either upload an image/screenshot of a document, or enter the text manually."
        )
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£çš„å›¾åƒ/å±å¹•æˆªå›¾ï¼š"
        )åœ¨è¿™ç¯‡æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ¶µç›–äº†å¤§é‡ä¿¡æ¯ï¼ŒåŒæ—¶è§£å†³äº†ä¸€äº›å¸¸è§çš„é—®é¢˜å’Œé—®é¢˜ï¼š

- ä½¿ç”¨ä¸åŒçš„ç´¢å¼•ç”¨äºä¸åŒçš„ç”¨ä¾‹ï¼ˆåˆ—è¡¨vs.å‘é‡ç´¢å¼•ï¼‰
- ä½¿ç”¨Streamlitçš„â€œsession_staâ€å­˜å‚¨å…¨å±€çŠ¶æ€å€¼æœ¬æ•™ç¨‹çš„æœ€ç»ˆç‰ˆæœ¬å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/logan-markewich/llama_index_starter_pack)æ‰¾åˆ°ï¼Œå¹¶ä¸”å¯ä»¥åœ¨[Huggingface Spaces](https://huggingface.co/spaces/llamaindex/llama_index_term_definition_demo)ä¸Šè®¿é—®ä¸€ä¸ªåœ¨çº¿æ¼”ç¤ºã€‚ä½¿ç”¨Llama Indexè‡ªå®šä¹‰å†…éƒ¨æç¤ºå’Œä»å›¾åƒä¸­è¯»å–æ–‡æœ¬ã€‚